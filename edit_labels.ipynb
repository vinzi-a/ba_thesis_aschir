{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "from tools import vis_picture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'non' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#problem of ending \"filopodia\" within eachother (coinciding)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR1_P30_1_270\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m vis_picture(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0022\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_path\u001b[38;5;241m=\u001b[39m\u001b[43mnon\u001b[49m , show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'non' is not defined"
     ]
    }
   ],
   "source": [
    "#problem of ending \"filopodia\" within eachother (coinciding)\n",
    "example=\"R1_P30_1_270\"\n",
    "vis_picture(filename=\"0022\", output_path=non , show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tool for editing copying or moving all the images from a folder to another one in parallel\n",
    "\n",
    "./change_dir.sh <type: bolean, delete old directory> <type: directory, origin directory> <type: directory, destination directory>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom files:\n",
      "already editet: 1416 and 0 failed. \n",
      "all 1417 custom files editet and 0 failed.\n",
      "generated_files:\n",
      "already editet: 999 and 0 failed. \n",
      "all 1000 generated files editet and 0 failed.\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "#edit bounding box \n",
    "#now let's change the bounding box size in the folder edit_labels. to the recommended 0.06 for custom data and 0.05 for generated data. \n",
    "./bounding_box_resize.sh \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/edit_labels\" 0.06 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@21.954] global loadsave.cpp:268 findDecoder imread_('data/custom_rot/images/0022.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0022\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mvis_picture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43mlabel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/custom_philo_generated/edit_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m vis_picture(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR1_P30_1_270\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     11\u001b[0m label_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/custom_philo_generated/labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     12\u001b[0m output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     13\u001b[0m show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     14\u001b[0m bounding_box\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m os\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/R1_P30_1_270_with_bounding_boxes.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/R1_P30_1_270_with_bounding_boxes2.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/tools.py:49\u001b[0m, in \u001b[0;36mvis_picture\u001b[0;34m(filename, image_path, label_path, pred_label_path, output_path, show, bounding_box)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# load the picture \u001b[39;00m\n\u001b[1;32m     48\u001b[0m  image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image) \n\u001b[0;32m---> 49\u001b[0m  image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m  scaley, scalex \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(image)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# load the labels\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#visualize the edited bounding box\n",
    "from tools import vis_picture\n",
    "import os\n",
    "example=\"0022\"\n",
    "\n",
    "vis_picture(filename=example, \n",
    "label_path= \"data/custom_philo_generated/edit_labels\", \n",
    "output_path=None, \n",
    "show=True)\n",
    "vis_picture(filename=\"R1_P30_1_270\", \n",
    "label_path=\"data/custom_philo_generated/labels\", \n",
    "output_path=\"output\", \n",
    "show=True, \n",
    "bounding_box=True)\n",
    "\n",
    "os.rename('output/R1_P30_1_270_with_bounding_boxes.jpg', 'output/R1_P30_1_270_with_bounding_boxes2.jpg')\n",
    "\n",
    "vis_picture(filename=\"R1_P30_1_270\", \n",
    "label_path=\"data/custom_philo_generated/edit_labels\", \n",
    "output_path=\"output\", \n",
    "show=True, \n",
    "bounding_box=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
