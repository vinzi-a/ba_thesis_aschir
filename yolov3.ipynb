{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov3 application on the filopodia \n",
    "1 Build the setup: \n",
    "Please make that your compiling kernel is set to a terminal in your enviral enviroment.\n",
    "the graphs and data information are gained with: *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the setup ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 19:38:39.801163: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-07 19:38:39.821470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741372719.854565   21222 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741372719.865098   21222 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 19:38:39.890027: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# libraries  \n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from pytorchyolo import detect, models, train, test\n",
    "from scipy.stats import gaussian_kde\n",
    "from natsort import natsorted\n",
    "from pyexcel_xlsx import get_data\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from tools import *\n",
    "import csv\n",
    "from IPython.display import Image\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['PATH'] = '/usr/local/cuda/bin:' + os.environ.get('PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "# ! export PATH=/usr/local/cuda/bin:$PATH\n",
    "# ! export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# set the working directory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your dir'"
     ]
    }
   ],
   "source": [
    "# set the working directory\n",
    "os.chdir( \"your dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the provided implemenation can only be conducdet in a gpu that support cuda. \n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of how the bounding box looks like on the origninal image\n",
    "example=\"R1_P30_1_270\"\n",
    "vis_picture(filename=\"R6_P40_4\",\n",
    "            image_path=\"data/custom_philo_generated/images\", \n",
    "            label_path=\"data/custom_philo_generated/labels\",\n",
    "            pred_label_path= \"data/custom_philo_generated/predicted_labels2\",\n",
    "            output_path=\"output\",\n",
    "            show=True,\n",
    "            bounding_box=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generated data ###\n",
    "generated data is not used in the filopodia tip detection serach by Vinzent Aschir, due to worst performance.   \n",
    "the alternative dataset is a mix between the labritory acquired data and 1000 images that are generated and provided by Eric Reifenstein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following cell will conclude the difference of including generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bounding_box_resize: tool for editing shifting all the images from a folder to another one in parallel\n",
    "\n",
    "./change_dir.sh <type: bolean, delete old directory> <type: directory, origin directory> <type: directory, destination directory>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "#edit bounding box \n",
    "#now let's change the bounding box size in the folder edit_labels. to the recommended 0.06 for custom data and 0.05 for generated data. \n",
    "#./bounding_box_resize.sh \"data/custom_philo_generated/edit_labels\" 0.06 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualisation range of accepted distance to be considered as a True Positive. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:836: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#vis: accepted distance  \u001b[39;00m\n\u001b[1;32m      2\u001b[0m example\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2_P35_1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;66;03m#R1_P30_1_270, R5_P40_10_270 R6_P28_8 R6_P35_9_270 R1_P35_0\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvis_picture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mR6_P40_10.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/custom_rot/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/custom_rot/labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpred_label_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#\"data/custom_philo_generated/predicted_labels\",\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvisualisation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#show bounding box\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mac_d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[38;5;66;43;03m# accepted distance drawn at 15 \u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/tools.py:156\u001b[0m, in \u001b[0;36mvis_picture\u001b[0;34m(filename, image_path, label_path, pred_label_path, output_path, show, bounding_box, ac_d)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# save the picture\u001b[39;00m\n\u001b[1;32m    155\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[0;32m--> 156\u001b[0m      \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m      \u001b[38;5;28;01mif\u001b[39;00m show \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m          \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:836: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'imwrite_'\n"
     ]
    }
   ],
   "source": [
    "#vis: accepted distance  \n",
    "example=\"R2_P35_1\"#R1_P30_1_270, R5_P40_10_270 R6_P28_8 R6_P35_9_270 R1_P35_0\n",
    "vis_picture(filename=\"R6_P40_10.jpg\",\n",
    "            image_path=\"data/custom_rot/images\", \n",
    "            label_path=\"data/custom_rot/labels\",\n",
    "            pred_label_path= None, #\"data/custom_philo_generated/predicted_labels\",\n",
    "            output_path=\"visualisation\",\n",
    "            show=True,\n",
    "            bounding_box=False, #show bounding box\n",
    "            ac_d=15# accepted distance drawn at 15 \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change_dir: tool for shifting all the files from one folder to another in parallel ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "via bash:\n",
    "#! ./change_dir.sh false \"/data/custom_philo_generated/labels\" \"data/custom_philo_generated/edit_labels\" true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#via python: \n",
    "cur_dir= \"./data/custom_philo_generated/labels_edit/\" #where the labels are saved\n",
    "bounding_box_custom = 0.06 #bounding box size custom data \n",
    "bb_gen = 0.05 # bounding box size generated data (none here) \n",
    "\n",
    "change_bb_cmd = [ #comand we wanna get excecuted by bash: \n",
    "    \"./bounding_box_resize.sh\", cur_dir, str(bounding_box_custom), str(bb_gen)\n",
    "]\n",
    "#subprocess.run(change_bb_cmd) #run the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./bounding_box_resize.sh: line 42: cd: ./data/custom_rot/labels_edit/: No such file or directory\n",
      "sed: couldn't edit __pycache__: not a regular file\n",
      "sed: sed: couldn't edit checkpoints: not a regular file\n",
      "couldn't edit config: not a regular file\n",
      "sed: couldn't edit csv: not a regular file\n",
      "sed: couldn't edit data: not a regular file\n",
      "sed: couldn't edit logs: not a regular file\n",
      "sed: couldn't edit output: not a regular file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom files:\n",
      "already editet: 26 and 0 failed. \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sed: couldn't edit pytorchyolo: not a regular file\n",
      "sed: couldn't edit visualisation: not a regular file\n",
      "sed: couldn't edit weights: not a regular file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already editet: 33 and 0 failed. \n",
      "all 34 custom files editet and 0 failed.\n",
      "generated_files:\n",
      "\n",
      "all 0 generated files editet and 0 failed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./bounding_box_resize.sh', './data/custom_rot/labels_edit/', '0.06', '0.05'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# change_dir.sh <type:bolean, \"delete content in destination folder\"> <source folder> <destination folder> <type:bolean, \"copy content instead of moving\">\n",
    "# ./change_dir.sh false \"/data/custom_philo_generated/labels\" \"data/custom_philo_generated/edit_labels\" true\n",
    "\n",
    "#resize bounding-boxes: \n",
    "cur_dir= \"./data/custom_philo_generated/labels_edit/\" #where the labels are saved\n",
    "bounding_box_custom = 0.06 #bounding box size custom data \n",
    "bb_gen = 0.05 # bounding box size generated data (none here) \n",
    "\n",
    "change_bb_cmd = [ #comand we wanna get excecuted by bash: \n",
    "    \"./bounding_box_resize.sh\", cur_dir, str(bounding_box_custom), str(bb_gen)\n",
    "]\n",
    "# subprocess.run(change_bb_cmd) #run the command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract and shape data out of original files\n",
    "In the next cell, the label files will be created and the oridinal data will be elarged by rotating every image by for times 90 degrees. For data access please contact Eric Reifenstein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receptor 1\n",
      "27 hAPF\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m         dat_xfront, dat_yfront \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(dat_fronts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 2\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39marray(dat_fronts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 3\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     dat_fronts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFront and Front Filopodia\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC, D\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     dat_xfront, dat_yfront \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(dat_fronts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 2\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39marray(dat_fronts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 3\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     47\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(dat_xfront\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/pandas/io/excel/_base.py:1554\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1552\u001b[0m     )\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n\u001b[1;32m   1559\u001b[0m engine \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_option(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.reader\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
     ]
    }
   ],
   "source": [
    " \n",
    "#%%\n",
    "# extract data from original files in the right format for yolov3 provided by Eric Reifenstein \n",
    "\n",
    "from tools import rotate_coord \n",
    "# from natsort import natsorted\n",
    "\n",
    "### changing parameters:\n",
    "boxsize = 0.06 # why this size?\n",
    "rotate = True # to elarge the data x4 by adding 3 rotated versions of the image \n",
    "\n",
    "#where we downloaded the data in: \n",
    "original_pic_directory = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/original_data/Single_Live_PR_Pictures\"\n",
    "original_label_directory = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/original_data/Filopodia_Base_Quantification\"\n",
    "\n",
    "#where we need the data to be for the training: \n",
    "destiny_pic_directory = \"data/custom_rot/images/\"\n",
    "destiny_label_directory = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/labels/\"\n",
    "###\n",
    "\n",
    "### get the data from the excel file and save it in the right format and place\n",
    "# loop over receptors and time points\n",
    "hours_save = [25, 30, 35, 40]\n",
    "for rec in [1, 2, 3, 4, 5, 6]:\n",
    "    print('Receptor ' + str(rec))\n",
    "    if rec == 1 or rec == 2 or rec == 5 or rec == 6:\n",
    "        hours = [27, 31, 36, 41]\n",
    "    elif rec == 3:\n",
    "        hours = [26, 30, 35, 40]\n",
    "    elif rec == 4:\n",
    "        hours = [27, 31, 36, 39]\n",
    "    \n",
    "    for hh, hour in enumerate(hours):\n",
    "        print(str(hour) + ' hAPF')\n",
    "        img_paths = natsorted(glob.glob(original_pic_directory + '/R' + str(rec) + '/P' + str(hours_save[hh]) + '/*'))\n",
    "        datpath = original_label_directory + '/R' + str(rec) + \"/R\"+ str(rec) + \"_\" + str(hour) + \"hAPF.xlsx\"\n",
    "        \n",
    "        if rec == 3: #load filopodia data from the excel file (split the data into subarrays based \"X\")\n",
    "            if hh == 0:\n",
    "                dat_fronts = pd.read_excel(datpath, usecols='D, E')\n",
    "                dat_xfront, dat_yfront = np.array(dat_fronts['Unnamed: 3']), np.array(dat_fronts['Unnamed: 4'])\n",
    "            else:\n",
    "                dat_fronts = pd.read_excel(datpath, usecols='C, D')\n",
    "                dat_xfront, dat_yfront = np.array(dat_fronts['Unnamed: 2']), np.array(dat_fronts['Unnamed: 3'])\n",
    "        else:\n",
    "            dat_fronts = pd.read_excel(datpath, sheet_name='Front and Front Filopodia', usecols='C, D')\n",
    "            dat_xfront, dat_yfront = np.array(dat_fronts['Unnamed: 2']), np.array(dat_fronts['Unnamed: 3'])\n",
    "        idx = np.where(dat_xfront=='X')[0]\n",
    "        subarrs_front_x = np.split(dat_xfront, idx+1)[1:]\n",
    "        subarrs_front_y = np.split(dat_yfront, idx+1)[1:]\n",
    "        \n",
    "        if rec != 3: \n",
    "            dat_heels = pd.read_excel(datpath, sheet_name='Heel and Heel Filopodia', usecols='C, D')\n",
    "            dat_xheel, dat_yheel = np.array(dat_heels['Unnamed: 2']), np.array(dat_heels['Unnamed: 3'])\n",
    "            idx = np.where(dat_xheel=='X')[0]\n",
    "            subarrs_heel_x = np.split(dat_xheel, idx+1)[1:]\n",
    "            subarrs_heel_y = np.split(dat_yheel, idx+1)[1:]\n",
    "        \n",
    "        for i, ip in enumerate(img_paths): #Load each image. Extract and process filopodia coordinates. Combine heel and front filopodia coordinates if applicable.\n",
    "            img = cv2.imread(ip)\n",
    "\n",
    "            xfil_front = np.array([elem for elem in subarrs_front_x[i] if isinstance(elem, (float, int)) and not np.isnan(elem)])[1:] # exclude front\n",
    "            yfil_front = np.array([elem for elem in subarrs_front_y[i] if isinstance(elem, (float, int)) and not np.isnan(elem)])[1:]\n",
    "            if rec == 3:\n",
    "                xfil = xfil_front.copy()\n",
    "                yfil = yfil_front.copy()\n",
    "            else:\n",
    "                xfil_heel = np.array([elem for elem in subarrs_heel_x[i] if isinstance(elem, (float, int)) and not np.isnan(elem)])[1:-1] # exclude heel and core border dot\n",
    "                yfil_heel = np.array([elem for elem in subarrs_heel_y[i] if isinstance(elem, (float, int)) and not np.isnan(elem)])[1:-1]\n",
    "                if rec == 5:\n",
    "                    xfil = np.r_[xfil_heel, xfil_front]\n",
    "                    yfil = 512 - np.r_[yfil_heel, yfil_front]\n",
    "                else:\n",
    "                    xfil = np.r_[xfil_heel, xfil_front]\n",
    "                    yfil = np.r_[yfil_heel, yfil_front]\n",
    "            \n",
    "            # plt.figure()\n",
    "            # plt.imshow(img)\n",
    "            # plt.scatter(xfil, yfil)\n",
    "            \n",
    "        ### create 3 rotated versions of the image\n",
    "        # rotate the data\n",
    "            if rotate: \n",
    "                img_90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "                x90, y90 = rotate_coord(xfil-512, yfil-256, np.pi/2)\n",
    "                x90 += 256\n",
    "                y90 += 512\n",
    "\n",
    "                img_180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "                x180, y180 = rotate_coord(xfil-512, yfil-256, np.pi)\n",
    "                x180 += 512\n",
    "                y180 += 256\n",
    "\n",
    "                img_270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                x270, y270 = rotate_coord(xfil-512, yfil-256, -np.pi/2)\n",
    "                x270 += 256\n",
    "                y270 += 512\n",
    "\n",
    "        # original data save \n",
    "            # save image \n",
    "            filename = \"R\"+str(rec)+\"_P\"+str(hours_save[hh])+\"_\"+str(i)\n",
    "            cv2.imwrite(destiny_pic_directory + filename + \".jpg\", img)    \n",
    "\n",
    "            # save labels\n",
    "            f = open(destiny_label_directory + filename + \".txt\", \"w\")\n",
    "            for j in range(len(xfil)):\n",
    "                # label_idx x_center y_center width height\n",
    "                # f.write(\"0 \" + str(xfil[j]/1024) + ' ' + str(yfil[j]/512) + ' ' + str(25/1024) + ' ' + str(25/512) + '\\n')\n",
    "                f.write(\"0 \" + str(xfil[j]/1024) + ' ' + str(yfil[j]/512) + ' ' + str(boxsize) + ' ' + str(boxsize) + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            if rotate: \n",
    "                # 90 degrees rotateted data save \n",
    "                filename = \"R\"+ str(rec) +\"_P\"+str(hours_save[hh])+\"_\"+str(i)+'_90'\n",
    "                cv2.imwrite(destiny_pic_directory + filename + \".jpg\", img_90)    \n",
    "\n",
    "                # save labels for training\n",
    "                f = open(destiny_label_directory + filename + \".txt\", \"w\")\n",
    "                for j in range(len(xfil)):\n",
    "                    # label_idx x_center y_center width height\n",
    "                    # f.write(\"0 \" + str(xfil[j]/1024) + ' ' + str(yfil[j]/512) + ' ' + str(25/1024) + ' ' + str(25/512) + '\\n')\n",
    "                    f.write(\"0 \" + str(x90[j]/512) + ' ' + str(y90[j]/1024) + ' ' + str(boxsize) + ' ' + str(boxsize) + '\\n')\n",
    "                f.close()\n",
    "\n",
    "                # 180 degrees rotateted data save\n",
    "                filename = \"R\"+str(rec)+\"_P\"+str(hours_save[hh])+\"_\"+str(i)+'_180'\n",
    "                cv2.imwrite(destiny_pic_directory + filename + \".jpg\", img_180)    \n",
    "\n",
    "                # save labels\n",
    "                f = open(destiny_label_directory + filename + \".txt\", \"w\")\n",
    "                for j in range(len(xfil)):\n",
    "                    # label_idx x_center y_center width height\n",
    "                    # f.write(\"0 \" + str(xfil[j]/1024) + ' ' + str(yfil[j]/512) + ' ' + str(25/1024) + ' ' + str(25/512) + '\\n')\n",
    "                    f.write(\"0 \" + str(x180[j]/1024) + ' ' + str(y180[j]/512) + ' ' + str(boxsize) + ' ' + str(boxsize) + '\\n')\n",
    "                f.close()\n",
    "\n",
    "                # 270 degrees rotateted data save\n",
    "                filename = \"R\"+str(rec)+\"_P\"+str(hours_save[hh])+\"_\"+str(i)+'_270'\n",
    "                cv2.imwrite(destiny_pic_directory + filename + \".jpg\", img_270)\n",
    "\n",
    "                # save labels for training\n",
    "                f = open(destiny_label_directory + filename + \".txt\", \"w\")\n",
    "                for j in range(len(xfil)):\n",
    "                    # label_idx x_center y_center width height\n",
    "                    # f.write(\"0 \" + str(xfil[j]/1024) + ' ' + str(yfil[j]/512) + ' ' + str(25/1024) + ' ' + str(25/512) + '\\n')\n",
    "                    f.write(\"0 \" + str(x270[j]/512) + ' ' + str(y270[j]/1024) + ' ' + str(boxsize) + ' ' + str(boxsize) + '\\n')\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xseed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# write train and valid file: (90% train, 10% validation)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m x_n_data, xval, xcust_only \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_train_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/custom_rot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcust_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/tools.py:285\u001b[0m, in \u001b[0;36mwrite_train_valid\u001b[0;34m(directory, val, cust_only, seed)\u001b[0m\n\u001b[1;32m    283\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/train.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m f2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/valid.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 285\u001b[0m allim \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[38;5;241m.\u001b[39mglob(root_dir\u001b[38;5;241m=\u001b[39m directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/images\u001b[39m\u001b[38;5;124m'\u001b[39m, pathname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    286\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m    287\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(allim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# write train and valid file: (90% train, 10% validation)\n",
    "\n",
    "x_n_data, xval, xcust_only = write_train_valid(directory=\"./data/custom_rot\",\n",
    "    val=0.1,\n",
    "    cust_only=True,\n",
    "    seed=xseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required folders and files are present.\n"
     ]
    }
   ],
   "source": [
    "#Add .train file \n",
    "ac_dir =\"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot\"\n",
    "\n",
    "#run the bash script to create the train file in the config folder (makes also the .names file if not present): \n",
    "! ./make_train_file.sh $ac_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xseed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     12\u001b[0m x_pretrained_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# \"checkpoints/yolov3_ckpt_25.pth\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m x_multi_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     15\u001b[0m training_cmd \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;66;03m#the command we wanna execute in a bash environment in a subprocess. \u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoetry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_yolo.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_model,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--data\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_data,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(x_epochs),\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--iou_thres\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(x_iou_thres),\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--conf_thres\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(x_conf_thres),\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--nms_thres\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(x_nms_thres),\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[43mxseed\u001b[49m),\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--n_cpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;66;03m#this is nessesary for not killing the data loader in the training.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--checkpoint_interval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#'--pretrained_weights', str(x_pretrained_weights), # comment this out if pretrained_weights is none.   \u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--multiscale_training\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_multi_scale \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#start the training in a subprocess: \u001b[39;00m\n\u001b[1;32m     30\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(training_cmd) \u001b[38;5;66;03m# create a new subprocess that the training doesn't affect the notebook. \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xseed' is not defined"
     ]
    }
   ],
   "source": [
    "#train the model: \n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# parameters for the training:\n",
    "x_model = \"config/yolov3-tiny-custom.cfg\" \n",
    "x_data = \"config/custom_rot.data\"\n",
    "x_epochs = 30\n",
    "x_iou_thres = 0.5 \n",
    "x_conf_thres = 0.2 #change \n",
    "x_nms_thres = 0.5\n",
    "x_pretrained_weights = None # \"checkpoints/yolov3_ckpt_25.pth\"\n",
    "x_multi_scale = True\n",
    "\n",
    "#for further paramater settings and the actual yolov3 cmd have a look at the train_yolo.py file.\n",
    "\n",
    "training_cmd = [ #the command we wanna execute in a bash environment in a subprocess. \n",
    "    \"poetry\", \"run\", \"python\", \"train_yolo.py\",\n",
    "    \"--model\", x_model,\n",
    "    \"--data\", x_data,\n",
    "    \"--epochs\", str(x_epochs),\n",
    "    \"--iou_thres\", str(x_iou_thres),\n",
    "    \"--conf_thres\", str(x_conf_thres),\n",
    "    \"--nms_thres\", str(x_nms_thres),\n",
    "    \"--seed\", str(xseed),\n",
    "    \"--n_cpu\", str(1), #this is nessesary for not killing the data loader in the training.\n",
    "    '--checkpoint_interval', str(5),\n",
    "    #'--pretrained_weights', str(x_pretrained_weights), # comment this out if pretrained_weights is none.   \n",
    "    \"--multiscale_training\" if x_multi_scale else ''\n",
    "]\n",
    "#start the training in a subprocess: \n",
    "process = subprocess.Popen(training_cmd) # create a new subprocess that the training doesn't affect the notebook. \n",
    "\n",
    "#TensorBoard_cmd = [\"poetry\", \"run\", \"tensorboard\", \"--logdir=logs\", \"--port=6006\"]\n",
    "#TensorBoard_process = subprocess.Popen(TensorBoard_cmd) # start the tensorboard for showing the progress.\n",
    "\n",
    "process.wait() # waiting until the subprocess and the training ended. \n",
    "\n",
    "tmp_file_path = 'train.tmp'\n",
    "if os.path.exists(tmp_file_path): \n",
    "    with open(tmp_file_path, 'r') as f:\n",
    "        x_train_time = f.read().strip()\n",
    "        os.remove(tmp_file_path)\n",
    "else:        \n",
    "    raise FileNotFoundError(\"The subprocess hasn't ended yet. The tmp file does not exist.\")\n",
    "\n",
    "# command for starting the training in a shell:\n",
    "\n",
    "#! poetry run python train_yolo.py --model $x_model  --data $x_data --epochs $x_epochs --iou_thres $x_iou_thres --conf_thres $x_conf_thres --nms_thres $x_nms_thres --seed $xseed --pretrained_weights $x_pretrained_weights --multiscale_training\n",
    "\n",
    "#track the training process: \n",
    "#!poetry run tensorboard --logdir='logs' --port=6006 #requires tensorboard and an poetry environment\n",
    "# see the process in the browser: http://localhost:6006/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/train_conf_thres/0.15 doesn_t exist yet.\n",
      "chmod: cannot access '755': No such file or directory\n",
      "\n",
      "all 6 files copied from ./checkpoints/ to /mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/train_conf_thres/0.15\n",
      "content deleted at: ./checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# this cell is to move output and weights to the right folder: \n",
    "ac_dir = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot\" \n",
    "dest_dir = ac_dir + \"/train_conf_thres/0.15\" \n",
    "\n",
    "! ./change_dir.sh true \"./checkpoints/\" $dest_dir true  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# to kill the subprocess with the training that we started in the background. \n",
    "process.terminate()\n",
    "if os.path.exists(\"train.tmp\"):\n",
    "    os.remove(\"train.tmp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "cell to store the setting for training and their results in an excel file: \n",
    "    which groundsettings did we use for the training? \n",
    "    which data how many pictures? \n",
    "    how much time did we take? \n",
    "    what is the result? with which settings? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/pytorchyolo/models.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0187\n",
      "TP:  17 , FP:  46 , FN:  0 , OD:  46 , NH:  0 , Sensitivity:  1.0 , predicted points:  10 , manual points:  17\n",
      "\n",
      " Number of pictures:  1 Number of not annotated pictures: 0 , Sensitivity:  1.0 , over detection rate:  2.705882 , no-hit-point-rate:  0.0 \n",
      "\n",
      "Bild mit Bounding Boxes gespeichert: None\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tools.statistix at 0x7f10439e2150>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to perform detection one one input picture. \n",
    "#the model should already be loaded to save time.\n",
    "\n",
    "#To DO: The issue is that we are not only doing the statistics here of the points, we are also doing the prediction. \n",
    "# do we outsource the prediction to another function? storing them in a file so we can also visualize them with the visualise function? \n",
    "\n",
    "#in the statistics: we should look ip in the matrix which coloumn didnt didnt got a minimum. that we can mark all the points in a different color for example that were over detected. \n",
    "#we can give as an output then the number of overdetected points. \n",
    "#we can also give the number of points that were not detected. \n",
    "#later we an build an extimator which points were well detected but not right in the given data? \n",
    "# check if in bounding box is something white? -> claim point as over detected -> no show the picture and add the point to the given data. \n",
    " \n",
    "from scipy.spatial import distance\n",
    "from tools import * \n",
    "from pytorchyolo import detect, models \n",
    "\n",
    "def detect_picture(filename=\"R1_P35_8_90\",\n",
    "                   img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/images\",\n",
    "                   pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/predicted_labels2\",\n",
    "                   model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"data/custom_philo_generated/checkpoints100/yolov3_ckpt_100.pth\"),\n",
    "                   conf_thres=0.01,\n",
    "                   nms_thres=0.1,\n",
    "                   accepted_distance = 35, # how many pixels are allowed between annotated and predicted point to be wrong?\n",
    "                   stat_all_pics= None, # for statistics is there an statistix object to store over every picture? \n",
    "                   output=None, # for visualisation: where should we store the visualized picture? None is possible! \n",
    "                   bounding_box = False, # for visualisation: should we show the bounding box?\n",
    "                   show = True):\n",
    "\n",
    "    #catching common errors\n",
    "\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.txt'): #check if the filename got also its ending. \n",
    "        filename= filename[:-len('.jpg')]\n",
    "\n",
    "    pic_path= f\"{img_path}/{filename}.jpg\"\n",
    "\n",
    "    if pred_label_path.endswith('.txt'):\n",
    "        raise TypeError(\"in the variable pred_label_path should contain only the directory not specific files.\")\n",
    "    \n",
    "    if img_path.endswith('.txt'):\n",
    "        raise TypeError(\"in the variable img_path should contain only the directory not specific files.\")\n",
    "\n",
    "    if not os.path.exists(pic_path):\n",
    "            raise FileNotFoundError(f\"Bild nicht gefunden: {pic_path}\")\n",
    " \n",
    "    #statistics inizialisation: \n",
    "    # if stat_all_pics is None: \n",
    "    #         stat_all_pics = statistix()\n",
    "    stat = stat_pic() #create a statistic object for one pic \n",
    "\n",
    "    if 'R3' not in filename: # heel filopodia are not annotated in the R3 manual data (this data is incomplete)\n",
    "    #parameters: \n",
    "        \n",
    "        #load the image\n",
    "        img = cv2.imread(pic_path)#.split('\\n')[0]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #get the absolute heights and widths of the image to scale the relative numbers back to the original size\n",
    "        img_height, img_width =img.shape[0], img.shape[1]\n",
    "        \n",
    "        #creates the label path to the given image_path\n",
    "        original_label_path = (pic_path.split('.jpg')[0] + '.txt').replace('images', 'labels')\n",
    "        \n",
    "        #load manual labels\n",
    "        original_labels = np.genfromtxt(original_label_path, delimiter=' ')#whats in the label file?\n",
    "\n",
    "    #load coordinates: \n",
    "        #put the relative coordinates back to absolute coordinates depending on their rotation:\n",
    "        pos_man = np.c_[original_labels[:, 1] * img_width, original_labels[:, 2] * img_height]           \n",
    "\n",
    "        boxes = detect.detect_image(model, img, conf_thres=conf_thres, nms_thres=nms_thres)\n",
    "        boxes=np.round(boxes,decimals=2)\n",
    "        \n",
    "        pos_pred = np.c_[(boxes[:, 0] + boxes[:, 2])/2, (boxes[:, 1] + boxes[:, 3])/2] #Umrechnung der Koordinaten auf die Mitte der Box.\n",
    "        \n",
    "        #store the predicted coordinates in a pred_label file: \n",
    "        predicted_labels = np.zeros((pos_pred.shape[0], 5))\n",
    "        predicted_labels[:, 0] = boxes[:,5]  # Copy class labels\n",
    "        predicted_labels[:, 2] = (boxes[:, 1] + boxes[:, 3]) / (2 * img_height) # Normalize x_center and y_center\n",
    "        predicted_labels[:, 1] = (boxes[:, 0] + boxes[:, 2]) / (2 * img_width)\n",
    "        predicted_labels[:, 3] = (boxes[:, 2] - boxes[:, 0]) / img_width # Normalize width and height\n",
    "        predicted_labels[:, 4] = (boxes[:, 3] - boxes[:, 1]) / img_height\n",
    "\n",
    "        #save the predicted labels in a new file\n",
    "        if pred_label_path is None:\n",
    "            pred_label_path = original_label_path.replace('labels', 'predicted_labels')\n",
    "        else: \n",
    "            if not os.path.exists(pred_label_path): ### sollte das nicht evtl in eine übergeordnete funktion die nicht per bild geht? \n",
    "                print(f\"Directory created: {pred_label_path}\")\n",
    "                os.makedirs(pred_label_path)\n",
    "                \n",
    "            pred_label_path_file = os.path.join(pred_label_path, filename) + '.txt'\n",
    "         # Save predicted labels to a new file this way to influence the float length. \n",
    "        with open(pred_label_path_file, 'w+') as f: \n",
    "            for row in predicted_labels:\n",
    "                f.write(f\"{int(row[0])} {row[1]:.6f} {row[2]:.6f} {row[3]:.2f} {row[4]:.2f}\\n\") #lets round the predicted coordinates.\n",
    "    \n",
    "        if show: \n",
    "            print(filename)\n",
    "            #print(f\"Predicted labels saved: {pred_label_path_file}\") ### evtl. weglassen man muss nicht alles anzeigen. \n",
    "    \n",
    "    #let's do the statistics:\n",
    "        \n",
    "        if not isinstance(stat_all_pics,statistix) and stat_all_pics is not None:\n",
    "            raise TypeError(\"stat_all_pics has not the input of a statistix object\")\n",
    "\n",
    "        D = distance.cdist(pos_pred, pos_man, metric = 'euclidean') # distance matrix\n",
    "        \n",
    "        stat.calculate(D, accepted_distance)\n",
    "        if stat_all_pics is not None: \n",
    "            stat_all_pics.add_pic(stat)\n",
    "            \n",
    "        if show: \n",
    "            stat.print_values() \n",
    "        if show and stat_all_pics is not None: \n",
    "            stat_all_pics.print_values() ### do we need them twice? maybe only per picture?\n",
    "        \n",
    "        filename=f\"{filename}.jpg\"\n",
    "        \n",
    "        vis_picture(filename=filename,\n",
    "                    image_path=img_path,\n",
    "                    label_path=img_path.replace('images', 'labels'),\n",
    "                    pred_label_path=pred_label_path,\n",
    "                    output_path=output, \n",
    "                    bounding_box=bounding_box,\n",
    "                    show=show\n",
    "                    )\n",
    "    # #add predicted and actual philopodia ends to the image:\n",
    "    #     for pm in pos_man: \n",
    "    #         cv2.circle(img, (int(pm[0]), int(pm[1])), 3, color=(0, 255, 0)) #green is the manual annotation\n",
    "    #     for pa in pos_pred:\n",
    "    #         cv2.circle(img, (int(pa[0]), int(pa[1])), 3, color=(0, 0, 255)) #blue is the predicted annotation\n",
    "    #     plt.figure()\n",
    "    #     plt.imshow(img)\n",
    "\n",
    "    else:\n",
    "        if show: \n",
    "            print(f'{filename} is R3 data and not annotated')\n",
    "            print()\n",
    "        stat.set_annotated()\n",
    "        if stat_all_pics is not None:\n",
    "            stat_all_pics.add_pic(stat)\n",
    "\n",
    "    return stat_all_pics\n",
    "\n",
    "mystats = statistix() \n",
    "model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"data/custom_philo_generated/checkpoints100/yolov3_ckpt_100.pth\") #load the trained model with its weights\n",
    "\n",
    "#detect_picture(stat_all_pics=mystats)\n",
    "\n",
    "#visualize the detections\n",
    "# vis_picture(img, detections)\n",
    "#  vis_picture(filename=\"R1_P35_8_90\",\n",
    "             # label_path=\"data/custom_philo_generated/labels\",\n",
    "             #pred\n",
    "             # output_path=\"output\", \n",
    "             # show=True,\n",
    "             # ) #label_path=\"../../yolo_test/data/custom/labels\",\n",
    "# def vis_picture(filename=\"R3_P35_22_90\",\n",
    "# image_path=f\"data/custom_philo_generated/images\", \n",
    "# ,\n",
    "# output_path=\"output\",\n",
    "# show=False):\n",
    "#R6_P40_10_180.jpg\n",
    "#R6_P40_11_180.jpg\n",
    "#R6_P40_7_90.jpg\n",
    "detect_picture(filename= \"0187.jpg\",\n",
    "                   img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/images\",\n",
    "                   pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/predicted_labels2\",\n",
    "                   model = model,\n",
    "                   conf_thres=0.01,\n",
    "                   nms_thres=0.1,\n",
    "                   accepted_distance = 35,\n",
    "                   stat_all_pics= mystats, \n",
    "                   show = True\n",
    "                )\n",
    "#detect_picture(filename=\"R6_P40_10_180\",img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/images\", stat_all_pics=mystats,show=False)\n",
    "#detect_picture(filename=\"R6_P40_7_90\",img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_philo_generated/images\", stat_all_pics=mystats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(original_label_path):\n",
    "            raise FileNotFoundError(f\"Labeldatei nicht gefunden: {original_label_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "Duration: 0d/0h/0m/9s\n",
      "\n",
      " Number of pictures:  141 Number of not annotated pictures: 53 , Sensitivity:  0 , over detection rate:  0 , no-hit-point-rate:  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Auswertung und erstellen der Statistik über alle Bilder  \n",
    "\n",
    "from pytorchyolo import detect, models\n",
    "import importlib\n",
    "import tools  \n",
    "#importlib.reload(tools) \n",
    "from tools import statistix, stat_pic, vis_picture\n",
    "from datetime import datetime\n",
    "\n",
    "#for tracking the compilation time\n",
    "start_time = datetime.now()\n",
    "\n",
    "all_stats = statistix() # create a statistic object \n",
    "\n",
    "file_val = open(\"data/custom_rot/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "#now we go through all the pictures we wanna add to the statistics: \n",
    "\n",
    "# Parameter:\n",
    "ev_conf_thres=0.01\n",
    "ev_nms_thres=0.1\n",
    "ev_accepted_distance=15\n",
    "model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"checkpoints/check_this\") #load the trained model with its weights\n",
    "\n",
    "for val_file in val_paths:\n",
    "    val_file = val_file.split('/')[-1]\n",
    "    detect_picture(filename= val_file.rstrip(),\n",
    "                   img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\",\n",
    "                   pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/predicted_labels\",\n",
    "                   model = model, #we use the once loaded model from the cell above to not waist time. \n",
    "                   conf_thres=ev_conf_thres,\n",
    "                   nms_thres=ev_nms_thres,\n",
    "                   accepted_distance = ev_accepted_distance,\n",
    "                   stat_all_pics= all_stats, \n",
    "                   show = False\n",
    "                )\n",
    "#stop the compilation time\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time \n",
    "\n",
    "# Calculate duration in d/h/m/s format\n",
    "days = duration.days\n",
    "hours, remainder = divmod(duration.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "duration_str = f\"{days}d/{hours}h/{minutes}m/{seconds}s\"\n",
    "ev_time=duration_str\n",
    "# Print the duration\n",
    "print('Duration:', duration_str)\n",
    "### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \n",
    "all_stats.print_values()\n",
    "x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate = all_stats.x_get_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visual breakdown of ten cells to see the acceptance range of an hitpoint.\n",
    "shown on 10 images and stored in the *output* directory. \n",
    "The thresholds can be adjusted based on the prefference of not having to many predicted points or or not so many _TP_.\n",
    "\n",
    "Also check on how strict you wanna be with the acceptance distance by looking into folder *visalisation/acceptance_distance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: target 'checkpoint/basline_100.pth': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/pytorchyolo/models.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m file_val\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m): \n\u001b[0;32m---> 14\u001b[0m     detect_picture(filename\u001b[38;5;241m=\u001b[39m \u001b[43mval_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     15\u001b[0m                    img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/custom_rot/images\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m                    pred_label_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/custom_rot/predicted_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m                    model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m     18\u001b[0m                    conf_thres\u001b[38;5;241m=\u001b[39mev_conf_thres,\n\u001b[1;32m     19\u001b[0m                    nms_thres\u001b[38;5;241m=\u001b[39mev_nms_thres,\n\u001b[1;32m     20\u001b[0m                    accepted_distance \u001b[38;5;241m=\u001b[39m ev_accepted_distance,\n\u001b[1;32m     21\u001b[0m                    stat_all_pics\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     22\u001b[0m                    output\u001b[38;5;241m=\u001b[39moutput,\n\u001b[1;32m     23\u001b[0m                    show \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m                 )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# visual breakdown 10 pic \n",
    "! cp data/custom_rot/valid.txt data/custom_rot/basline/yolov3_ckpt_100.pth checkpoint/basline_100.pth\n",
    "#parameters\n",
    "ev_conf_thres=0.01\n",
    "ev_nms_thres=0.1\n",
    "ev_accepted_distance=15\n",
    "model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"checkpoints/baseline_100.pth\") \n",
    "\n",
    "#wir könnten nochmal 10 zufällige aus der Validation datei ziehen, dadurch dass diese Datei aber in einer zufälligen Reihenfolge gezogen wurde, schauen wir uns einfach die ersten 10 an. \n",
    "file_val = open(\"data/custom_rot/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "for i in range(10): \n",
    "    detect_picture(filename= val_paths[i].rstrip().split('/')[-1],\n",
    "                   img_path = \"data/custom_rot/images\",\n",
    "                   pred_label_path = \"data/custom_rot/predicted_labels\",\n",
    "                   model = model,\n",
    "                   conf_thres=ev_conf_thres,\n",
    "                   nms_thres=ev_nms_thres,\n",
    "                   accepted_distance = ev_accepted_distance,\n",
    "                   stat_all_pics= None, \n",
    "                   output=output,\n",
    "                   show = True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell in wsl:  True cwd in windows:  True\n",
      "NVIDIA GeForce MX450\n",
      "Aktuelles Datum und Zeit: 2025-02-12 13:25:11\n"
     ]
    }
   ],
   "source": [
    "#current Date, Gpu, is wsl, cwd in windows\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# current time \n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\") #format the time \n",
    "\n",
    "# current gpu \n",
    "x_gpu =torch.cuda.get_device_name(0) # extract the gpu name \n",
    "\n",
    "#current working env \n",
    "def detect_environment():\n",
    "    in_wsl = False\n",
    "    in_windows = False\n",
    "\n",
    "    # Prüfen, ob WSL läuft\n",
    "    try:\n",
    "        with open(\"/proc/sys/kernel/osrelease\", \"r\") as f:\n",
    "            in_wsl = \"WSL\" in f.read()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Prüfen, ob das Working Directory in Windows ist\n",
    "    cwd = os.getcwd()\n",
    "    in_windows = cwd.startswith(\"/mnt/\")\n",
    "    \n",
    "    return in_wsl, in_windows\n",
    "\n",
    "in_wsl, in_windows = detect_environment()\n",
    "print(\"shell in wsl: \", in_wsl, \"cwd in windows: \", in_windows)\n",
    "print(x_gpu)\n",
    "print(\"Aktuelles Datum und Zeit:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data= \"config/custom_rot.data\"\n",
    "x_train_time =\"0d/13h/15m/43s\" # time of baseline 100\n",
    "x_model= \"config/yolov3-tiny-custom.cfg\"\n",
    "x_epochs= 30\n",
    "x_pretrained_weights=None\n",
    "x_iou_thres= 0.5\n",
    "x_conf_thres= 0.1\n",
    "x_nms_thres= 0.5\n",
    "x_multi_scale= True\n",
    "xseed= 42\n",
    "\n",
    "rotate=True\n",
    "boxsize=0.06\n",
    "x_n_gen=None\n",
    "x_bb_gen=None\n",
    "\n",
    "k_cross_val=1\n",
    "xcust_only=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "key=\"ev_conf_thres\" #the key is a field for metadata, to group multiple rows belonging together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: ev_conf_thres\n",
      "\n",
      " the data parameters: \n",
      "     data: config/custom_rot.data\n",
      "     custom pictures are rotated: True\n",
      "     bounding-box-size for custom data: 0.06\n",
      "     amount of generated data included in the training process: None\n",
      "     bounding_box-size used for the generated data: None\n",
      "     amount of pictures in the data: 1416\n",
      "     percentage of data used for validation: 0.1\n",
      "     did we use only custom data for the validation (no generated): True\n",
      "\n",
      "the training parameters: \n",
      "     the neuronal network model: config/yolov3-tiny-custom.cfg\n",
      "     how many epochs were trained:  30\n",
      "     pretrained weights: None \n",
      "     did you use the built-in multiscaling tool for elarging your data: True \n",
      "     training iou threshold: 0.5 \n",
      "     training confidence threshold: 0.1 \n",
      "     training nms threshold: 0.5\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'current_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe training parameters: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m    the neuronal network model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m    how many epochs were trained:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m    training confidence threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_conf_thres\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m    training nms threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_nms_thres\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# verify if these are the general notebook settings you used/achieved:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe general notebook settings: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m    the used seed in your notebook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;124m    the current date and time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcurrent_time\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m    the time the training took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124m    the time the evaluation took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mev_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124m    the k-fold cross validation you used: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_cross_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m    the gpu you used: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_gpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m    shell im wsl: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_wsl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m    current working directory in windows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_windows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# verify if these are the achieved values and used parameters for the statistic:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe statistical result/ parameters: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124m    cells were not annotated and excluded in the statistics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_n_not_annotated\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m    sensitivity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(x_sens,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m    over detection rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(x_over_det_rate,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m    no hit point rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(x_no_hit_p_rate,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_time' is not defined"
     ]
    }
   ],
   "source": [
    "#check parameters: that all values are correct before adding them to the csv file.\n",
    " \n",
    "### split everything in different cells.\n",
    "\n",
    "# verify if these are the parameters you used for the data: \n",
    "print(f\"key: {key}\\n\")\n",
    "\n",
    "print(f\" the data parameters: \\n \\\n",
    "    data: {x_data}\\n \\\n",
    "    custom pictures are rotated: {rotate}\\n \\\n",
    "    bounding-box-size for custom data: {boxsize}\\n \\\n",
    "    amount of generated data included in the training process: {x_n_gen}\\n \\\n",
    "    bounding_box-size used for the generated data: {x_bb_gen}\\n \\\n",
    "    amount of pictures in the data: {x_n_data}\\n \\\n",
    "    percentage of data used for validation: {xval}\\n \\\n",
    "    did we use only custom data for the validation (no generated): {xcust_only}\\n\")\n",
    "\n",
    "# verify if these are the parameters you used for the training:\n",
    "print(f\"the training parameters: \\n \\\n",
    "    the neuronal network model: {x_model}\\n \\\n",
    "    how many epochs were trained:  {x_epochs}\\n \\\n",
    "    pretrained weights: {x_pretrained_weights} \\n \\\n",
    "    did you use the built-in multiscaling tool for elarging your data: {x_multi_scale} \\n \\\n",
    "    training iou threshold: {x_iou_thres} \\n \\\n",
    "    training confidence threshold: {x_conf_thres} \\n \\\n",
    "    training nms threshold: {x_nms_thres}\\n\")\n",
    "\n",
    "# verify if these are the general notebook settings you used/achieved:\n",
    "print(f\"the general notebook settings: \\n \\\n",
    "    the used seed in your notebook: {xseed}\\n \\\n",
    "    the current date and time: {current_time}\\n \\\n",
    "    the time the training took: {x_train_time}\\n \\\n",
    "    the time the evaluation took: {ev_time}\\n \\\n",
    "    the k-fold cross validation you used: {k_cross_val}\\n \\\n",
    "    the gpu you used: {x_gpu}\\n \\\n",
    "    shell im wsl: {in_wsl} \\n \\\n",
    "    current working directory in windows: {in_windows}\\n\")\n",
    "\n",
    "# verify if these are the achieved values and used parameters for the statistic:\n",
    "print(f\"the statistical result/ parameters: \\n \\\n",
    "    cells were not annotated and excluded in the statistics: {x_n_not_annotated}\\n \\\n",
    "    sensitivity: {round(x_sens, 4)}\\n \\\n",
    "    over detection rate: {round(x_over_det_rate, 4)}\\n \\\n",
    "    no hit point rate: {round(x_no_hit_p_rate, 4)}\\n\")\n",
    "\n",
    "# verify if these are the parameters you used for the evaluation:\n",
    "print(f\"the evaluation parameters: \\n \\\n",
    "    confidence threshold for the evaluation: {ev_conf_thres}\\n \\\n",
    "    nms threshold for the evaluation: {ev_nms_thres}\\n \\\n",
    "    accepted distance for the evaluation: {ev_accepted_distance}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you checked all the Parameters above, for your training process, then you can add them to your csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create csv: \n",
    "import csv \n",
    "with open('train_conf_thres2.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    field = [\"key\", \n",
    "             \"data\", \"custom_rotated\", \"bounding_box_custom\", \"n_generated\", \"bounding_box_generated\", \"n_data\",\t\"val_perc\", \"val_cust_only\",\n",
    "             \"train_model\", \"train_epochs\", \"train_pretrained_weights\", \"train_multiscale_training\", \"train_iou_thres\", \"train_conf_thres\", \"train_nms_thres\",\n",
    "             \"seed\", \"gpu\", \"current_time\", \"training_time\", \"ev_time\", \"k_cross_val\", \"shell_in_wsl\", \"cwd_in_windows\",\n",
    "             \"n_not_annotated\", \"sens\", \"over_detecion_rate\", \"no_hit_point_rate\",\n",
    "             \"ev_conf_thres\", \"ev_nms_thres\", \"accepted_dist\"]\n",
    "    writer.writerow(field)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# add an line to the csv file: \n",
    "# the key is a field for comments as metadata, for marking different cells belonging together. \n",
    "with open('train_conf_thres.csv', 'a', newline='') as file:\n",
    "    writer= csv.writer(file)\n",
    "    writer.writerow([key,\n",
    "                     x_data, rotate, boxsize, x_n_gen, x_bb_gen, x_n_data, xval, xcust_only,\n",
    "                     x_model, x_epochs, x_pretrained_weights, x_multi_scale, x_iou_thres, x_conf_thres, x_nms_thres,\n",
    "                     xseed, x_gpu, current_time, x_train_time,ev_time, k_cross_val, in_wsl, in_windows,\n",
    "                     x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate,\n",
    "                     ev_conf_thres, ev_nms_thres, ev_accepted_distance])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def csv_delete_row(doc='train_documentation.csv', index=-1):\t#needs pandas library as pd \n",
    "    #checks if input is an csv file: \n",
    "    is_csv=doc.lower().endswith('.csv')\n",
    "    if not is_csv:\n",
    "        raise TypeError(\"The input file is not a csv file.\")\n",
    "    else:\n",
    "        df = pd.read_csv('train_documentation.csv')\n",
    "        df = df.drop(df.index[-1]) #delete last column else change -1 to specified index. \n",
    "        df.to_csv('train_documentation.csv', index=False)\n",
    "\n",
    "def csv_delete_by_key(doc='train_documentation.csv', key=\"test\"): #needs pandas library as pd \n",
    "    #checks if input is an csv file: \n",
    "    is_csv=doc.lower().endswith('.csv')\n",
    "    if not is_csv:\n",
    "        raise TypeError(\"The input file is not a csv file.\")\n",
    "    else:\n",
    "        df = pd.read_csv(doc)\n",
    "        df = df[df.key != key] #delete last column else change -1 to specified index. \n",
    "        df.to_csv(doc, index=False)\n",
    "\n",
    "\n",
    "csv_delete_row()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets visualize the results: in the example train_nms_thres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the r3 Data, where heel filopodia are not annotated. \n",
    "# \n",
    "import glob\n",
    "import re\n",
    "\n",
    "directory = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\"\n",
    "\n",
    "# store all R3 files \n",
    "all_files = glob.glob(f\"{directory}/R3*.jpg\") \n",
    "\n",
    "# filtering the rotations out with regular expression: \"R3_P<number>_<number>.jpg\" for \n",
    "pattern = re.compile(r\"^R3_P\\d+_\\d+\\.jpg$\") \n",
    "\n",
    "r3_files = [os.path.basename(f) for f in all_files if pattern.search(f.split('/')[-1])]\n",
    "print(\"amount of R3 images:\", len(r3_files))\n",
    "#print(filtered_files)\n",
    "\n",
    "for i in r3_files: \n",
    "    vis_picture(filename=i,\n",
    "        image_path=\"data/custom_philo_generated/images\", \n",
    "        label_path=\"data/custom_philo_generated/labels\",\n",
    "        pred_label_path=None,\n",
    "        output_path= None, # \"visualisation/R3\",\n",
    "        show= False,\n",
    "        bounding_box=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/pytorchyolo/models.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total amount of images:  1416 validation amount:  1416 training amount:  0\n",
      "Duration: 0d/0h/3m/8s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration:\u001b[39m\u001b[38;5;124m'\u001b[39m, duration_str)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mall_stats\u001b[49m\u001b[38;5;241m.\u001b[39mprint_values()\n\u001b[1;32m     60\u001b[0m x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate \u001b[38;5;241m=\u001b[39m all_stats\u001b[38;5;241m.\u001b[39mx_get_values()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_stats' is not defined"
     ]
    }
   ],
   "source": [
    "#all custom_rot data: Visualization and evaluation of \n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "#baseline parameters:\n",
    "val_perc=1\n",
    "cust_only=True \n",
    "x_seed=42\n",
    "data= \"data/custom_rot\"\n",
    "\n",
    "x_ev_conf_thres=0.01\n",
    "x_ev_nms_thres=0.1\n",
    "x_ev_accepted_distance=15\n",
    "x_model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"checkpoints/baseline_100.pth\")\n",
    "bounding_box_custom = 0.06\n",
    "\n",
    "#create an statistic object for evaluation. \n",
    "stat_all = statistix()\n",
    "\n",
    "#have a look at the dir of this variable: \n",
    "visualisation = \"data/custom_rot/visualisaion_base_all\"\n",
    "write_train_valid(directory= data, val=val_perc, cust_only=cust_only, seed=x_seed)\n",
    "\n",
    "file_val = open(data+\"/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "\n",
    "for val_file in val_paths:\n",
    "    val_file= val_file.split('/')[-1]\n",
    "    detect_picture(filename= val_file.rstrip(),\n",
    "               img_path = data + \"/images\",\n",
    "               pred_label_path =  data + \"/predicted_labels_a_base\",\n",
    "               model = x_model, #models.load_model(\"config/yolov3-tiny-custom.cfg\", \"data/custom_philo_generated/checkpoints100/yolov3_ckpt_100.pth\"),\n",
    "               conf_thres=x_ev_conf_thres,\n",
    "               nms_thres= x_ev_nms_thres,\n",
    "               accepted_distance = x_ev_accepted_distance, # how many pixels are allowed between annotated and predicted point to be wrong?\n",
    "               stat_all_pics= stat_all, # for statistics is there an statistix object to store over every picture? \n",
    "               output=visualisation, # for visualisation: where should we store the visualized picture? None is possible! \n",
    "               bounding_box = False, # for visualisation: should we show the bounding box?\n",
    "               show = False, \n",
    "               ac_d=x_ev_accepted_distance #for visualisation: accepted distance between annotated and predicted point\n",
    "        )\n",
    "#stop the compilation time\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time \n",
    "\n",
    "# Calculate duration in d/h/m/s format\n",
    "days = duration.days\n",
    "hours, remainder = divmod(duration.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "duration_str = f\"{days}d/{hours}h/{minutes}m/{seconds}s\"\n",
    "ev_time=duration_str\n",
    "# Print the duration\n",
    "print('Duration:', duration_str)\n",
    "### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \n",
    "stat_all.print_values()\n",
    "x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate = stat_all.x_get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>data</th>\n",
       "      <th>custom_rotated</th>\n",
       "      <th>bounding_box_custom</th>\n",
       "      <th>n_generated</th>\n",
       "      <th>bounding_box_generated</th>\n",
       "      <th>n_data</th>\n",
       "      <th>val_perc</th>\n",
       "      <th>val_cust_only</th>\n",
       "      <th>train_model</th>\n",
       "      <th>...</th>\n",
       "      <th>training_time</th>\n",
       "      <th>ev_time</th>\n",
       "      <th>k_cross_val</th>\n",
       "      <th>n_not_annotated</th>\n",
       "      <th>sens</th>\n",
       "      <th>over_detecion_rate</th>\n",
       "      <th>no_hit_point_rate</th>\n",
       "      <th>ev_conf_thres</th>\n",
       "      <th>ev_nms_thres</th>\n",
       "      <th>accepted_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first_baseline</td>\n",
       "      <td>config/custom_rot.data</td>\n",
       "      <td>True</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1416</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>config/yolov3-tiny-custom.cfg</td>\n",
       "      <td>...</td>\n",
       "      <td>0d/2h/45m/1s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.642523</td>\n",
       "      <td>0.193146</td>\n",
       "      <td>0.034368</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              key                    data  custom_rotated  \\\n",
       "0  first_baseline  config/custom_rot.data            True   \n",
       "\n",
       "   bounding_box_custom  n_generated  bounding_box_generated  n_data  val_perc  \\\n",
       "0                 0.06          NaN                     NaN    1416       0.1   \n",
       "\n",
       "   val_cust_only                    train_model  ...  training_time  ev_time  \\\n",
       "0           True  config/yolov3-tiny-custom.cfg  ...   0d/2h/45m/1s      NaN   \n",
       "\n",
       "   k_cross_val  n_not_annotated      sens  over_detecion_rate  \\\n",
       "0            1               53  0.642523            0.193146   \n",
       "\n",
       "   no_hit_point_rate ev_conf_thres  ev_nms_thres  accepted_dist  \n",
       "0           0.034368          0.01           0.1             35  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path= \"train_documentation.csv\" \n",
    "\n",
    "#read the csv file:\n",
    "df = pd.read_csv(csv_file_path) \n",
    "df.head() #show the first 5 rows of the csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild mit Bounding Boxes gespeichert: output\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "There are no manual points in this picture.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val_file \u001b[38;5;129;01min\u001b[39;00m val_paths:\n\u001b[1;32m     31\u001b[0m     val_file \u001b[38;5;241m=\u001b[39m val_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mdetect_picture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpred_label_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/predicted_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#we use the once loaded model from the cell above to not waist time. \u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconf_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mev_conf_thres\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnms_thres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mev_nms_thres\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43maccepted_distance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mev_accepted_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstat_all_pics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mall_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#stop the compilation time\u001b[39;00m\n\u001b[1;32m     43\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/tools.py:369\u001b[0m, in \u001b[0;36mdetect_picture\u001b[0;34m(filename, img_path, pred_label_path, model, conf_thres, nms_thres, accepted_distance, stat_all_pics, output, bounding_box, show)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstat_all_pics has not the input of a statistix object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m D \u001b[38;5;241m=\u001b[39m distance\u001b[38;5;241m.\u001b[39mcdist(pos_pred, pos_man, metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# distance matrix\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m \u001b[43mstat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_all_pics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m    371\u001b[0m     stat_all_pics\u001b[38;5;241m.\u001b[39madd_pic(stat)\n",
      "File \u001b[0;32m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/tools.py:237\u001b[0m, in \u001b[0;36mstat_pic.calculate\u001b[0;34m(self, distance_matrix, accepted_distance)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msensitivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are no manual points in this picture.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: There are no manual points in this picture."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph: checkpoints - this cell is to find out which amount of checkpoints is the best for the model. \n",
    "#Auswertung und erstellen der Statistik über alle Bilder  \n",
    "\n",
    "from pytorchyolo import detect, models\n",
    "import importlib\n",
    "import tools  \n",
    "importlib.reload(tools) \n",
    "from tools import statistix, stat_pic, vis_picture\n",
    "from datetime import datetime\n",
    "\n",
    "file_val = open(\"data/custom_rot/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "\n",
    "for ckpt in range(1, 101,2): #go through all the checkpoints from 1 to 100 in steps of 5. \n",
    "    #for tracking the compilation time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    model = models.load_model(\"config/yolov3-tiny-custom.cfg\", f\"checkpoints/yolov3_ckpt_{ckpt}.pth\") #load the trained model with its weights\n",
    "\n",
    "    all_stats = statistix() # create a statistic object \n",
    "\n",
    "    \n",
    "    #now we go through all the pictures we wanna add to the statistics: \n",
    "    # Parameter:\n",
    "    ev_conf_thres=0.5\n",
    "    ev_nms_thres=0.5\n",
    "    ev_accepted_distance=15\n",
    "\n",
    "    for val_file in val_paths:\n",
    "        val_file = val_file.split('/')[-1]\n",
    "        detect_picture(filename= val_file.rstrip(),\n",
    "                    img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\",\n",
    "                    pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/predicted_labels\",\n",
    "                    model = model, #we use the once loaded model from the cell above to not waist time. \n",
    "                    conf_thres=ev_conf_thres,\n",
    "                    nms_thres=ev_nms_thres,\n",
    "                    accepted_distance = ev_accepted_distance,\n",
    "                    stat_all_pics= all_stats, \n",
    "                    show = False\n",
    "                    )\n",
    "    #stop the compilation time\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time \n",
    "\n",
    "    # Calculate duration in d/h/m/s format\n",
    "    days = duration.days\n",
    "    hours, remainder = divmod(duration.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    duration_str = f\"{days}d/{hours}h/{minutes}m/{seconds}s\"\n",
    "    ev_time=duration_str\n",
    "    # Print the duration\n",
    "    print('Duration:', duration_str)\n",
    "    ### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \n",
    "    all_stats.print_values\n",
    "    x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate = all_stats.x_get_values()\n",
    "    \n",
    "    x_epochs=ckpt\n",
    "    #write to csv: \n",
    "    with open('baseline_ckpts.csv', 'a', newline='') as file:\n",
    "        writer= csv.writer(file)\n",
    "        writer.writerow([key,\n",
    "                         x_data, rotate, boxsize, x_n_gen, x_bb_gen, x_n_data, xval, xcust_only,\n",
    "                         x_model, x_epochs, x_pretrained_weights, x_multi_scale, x_iou_thres, x_conf_thres, x_nms_thres,\n",
    "                         xseed, x_train_time,ev_time, k_cross_val,\n",
    "                         x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate,\n",
    "                         ev_conf_thres, ev_nms_thres, ev_accepted_distance])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Graph: ev nms threshold:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Graph: checkpoints - this cell is to find out which amount of checkpoints is the best for the model. \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Auswertung und erstellen der Statistik über alle Bilder  \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorchyolo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect, models\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtools\u001b[39;00m  \n",
      "File \u001b[0;32m/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/pytorchyolo/detect.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Variable\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torchvision/models/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torchvision/models/convnext.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torchvision/ops/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torchvision/ops/poolers.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torchvision/ops/roi_align.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:53\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m     _disable_current_modes,\n\u001b[1;32m     49\u001b[0m     is_in_torch_dispatch_mode,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback, format_traceback_short\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     56\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[1;32m     57\u001b[0m     Instruction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     transform_code_object,\n\u001b[1;32m     61\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     BuiltinVariable,\n\u001b[1;32m     48\u001b[0m     FunctionalCallVariable,\n\u001b[1;32m     49\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     50\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     51\u001b[0m     PolyfilledFunctionVariable,\n\u001b[1;32m     52\u001b[0m     SkipFunctionVariable,\n\u001b[1;32m     53\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[1;32m     54\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     55\u001b[0m     UserMethodVariable,\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     59\u001b[0m np: Optional[types\u001b[38;5;241m.\u001b[39mModuleType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/variables/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctx_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     CatchWarningsCtxManagerVariable,\n\u001b[1;32m      6\u001b[0m     ContextWrappingVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     WithExitFunctionVariable,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MutableLocal, VariableTracker\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctx_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EventVariable, StreamVariable\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdicts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     ConstDictVariable,\n\u001b[1;32m     50\u001b[0m     DefaultDictVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     SetVariable,\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlists\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     57\u001b[0m     BaseListVariable,\n\u001b[1;32m     58\u001b[0m     ListIteratorVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     TupleVariable,\n\u001b[1;32m     63\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/variables/ctx_manager.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttrSource, GlobalStateSource\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     24\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     25\u001b[0m     UserMethodVariable,\n\u001b[1;32m     26\u001b[0m     WrappedUserFunctionVariable,\n\u001b[1;32m     27\u001b[0m     WrappedUserMethodVariable,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_defined\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserDefinedObjectVariable\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:31\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_composable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fsdp_param_group\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     _fsdp_param_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov3/lib/python3.12/site-packages/torch/distributed/_composable/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_activation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m checkpoint\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_registry, contract\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_shard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fully_shard\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1187\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Graph: ev nms threshold:\n",
    "#Graph: checkpoints - this cell is to find out which amount of checkpoints is the best for the model. \n",
    "#Auswertung und erstellen der Statistik über alle Bilder  \n",
    "\n",
    "from pytorchyolo import detect, models\n",
    "import importlib\n",
    "import tools  \n",
    "importlib.reload(tools) \n",
    "from tools import statistix, stat_pic, vis_picture\n",
    "from datetime import datetime\n",
    "\n",
    "file_val = open(\"data/custom_rot/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "\n",
    "nms_steps =  np.arange(0.6, 1, 0.01)  # Note: The stop value is exclusive, so use 0.6 to include 0.5\n",
    "\n",
    "\n",
    "for step in nms_steps: #go through all the checkpoints from 1 to 100 in steps of 5. \n",
    "    #for tracking the compilation time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"checkpoints/yolov3_ckpt_100.pth\") #load the trained model with its weights\n",
    "\n",
    "    all_stats = statistix() # create a statistic object \n",
    "\n",
    "    \n",
    "    #now we go through all the pictures we wanna add to the statistics: \n",
    "    # Parameter:\n",
    "    ev_conf_thres=0.01\n",
    "    ev_nms_thres=step\n",
    "    ev_accepted_distance=15\n",
    "\n",
    "    for val_file in val_paths:\n",
    "        val_file = val_file.split('/')[-1]\n",
    "        detect_picture(filename= val_file.rstrip(),\n",
    "                    img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\",\n",
    "                    pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/predicted_labels\",\n",
    "                    model = model, #we use the once loaded model from the cell above to not waist time. \n",
    "                    conf_thres=ev_conf_thres,\n",
    "                    nms_thres=ev_nms_thres,\n",
    "                    accepted_distance = ev_accepted_distance,\n",
    "                    stat_all_pics= all_stats, \n",
    "                    show = False\n",
    "                    )\n",
    "\n",
    "    #compilation time\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time \n",
    "\n",
    "    days = duration.days\n",
    "    hours, remainder = divmod(duration.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    duration_str = f\"{days}d/{hours}h/{minutes}m/{seconds}s\"\n",
    "    ev_time=duration_str\n",
    "\n",
    "    print('Duration:', duration_str)\n",
    "    ### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \n",
    "    all_stats.print_values\n",
    "    x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate = all_stats.x_get_values()\n",
    "    \n",
    "    x_epochs=100\n",
    "\n",
    "    #write to csv: \n",
    "    with open('ev_nms_thres.csv', 'a', newline='') as file:\n",
    "        writer= csv.writer(file)\n",
    "        writer.writerow([key,\n",
    "                         x_data, rotate, boxsize, x_n_gen, x_bb_gen, x_n_data, xval, xcust_only,\n",
    "                         x_model, x_epochs, x_pretrained_weights, x_multi_scale, x_iou_thres, x_conf_thres, x_nms_thres,\n",
    "                         xseed, x_train_time,ev_time, k_cross_val,\n",
    "                         x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate,\n",
    "                         ev_conf_thres, ev_nms_thres, ev_accepted_distance])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: no predicted points in R4_P40_3\n",
      "0.15\n",
      "box: no predicted points in R4_P40_3\n",
      "0.175\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R1_P35_4_180\n",
      "0.19999999999999998\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "0.22499999999999998\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "0.24999999999999997\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.27499999999999997\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.29999999999999993\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.32499999999999996\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.35\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.37499999999999994\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.3999999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.42499999999999993\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.44999999999999996\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.475\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.4999999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.5249999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.5499999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.575\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.5999999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.6249999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.6499999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.6749999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.6999999999999998\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.7249999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.7499999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.7749999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.7999999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.8249999999999998\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.8499999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.8749999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.8999999999999998\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.9249999999999998\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.9499999999999998\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.9749999999999999\n",
      "box: no predicted points in R1_P30_9_90\n",
      "box: no predicted points in R4_P40_11_90\n",
      "box: no predicted points in R6_P25_8\n",
      "box: no predicted points in R4_P25_4_90\n",
      "box: no predicted points in R4_P40_5_270\n",
      "box: no predicted points in R2_P25_1_270\n",
      "box: no predicted points in R4_P25_10_180\n",
      "box: no predicted points in R6_P30_5_180\n",
      "box: no predicted points in R6_P25_2_180\n",
      "box: no predicted points in R4_P40_3\n",
      "box: no predicted points in R4_P35_0\n",
      "box: no predicted points in R1_P35_0_270\n",
      "box: no predicted points in R5_P25_3_90\n",
      "box: no predicted points in R5_P25_0\n",
      "box: no predicted points in R4_P30_2_180\n",
      "box: no predicted points in R2_P25_10_90\n",
      "box: no predicted points in R1_P35_7_270\n",
      "box: no predicted points in R4_P40_8_90\n",
      "box: no predicted points in R1_P25_8\n",
      "box: no predicted points in R4_P40_11\n",
      "box: no predicted points in R2_P25_7_270\n",
      "box: no predicted points in R2_P40_8_270\n",
      "box: no predicted points in R2_P35_0\n",
      "box: no predicted points in R5_P35_6_270\n",
      "box: no predicted points in R5_P30_10_180\n",
      "box: no predicted points in R5_P35_4\n",
      "box: no predicted points in R1_P30_2\n",
      "box: no predicted points in R1_P25_1_270\n",
      "box: no predicted points in R5_P40_1\n",
      "box: no predicted points in R5_P25_2\n",
      "box: no predicted points in R2_P40_8_90\n",
      "box: no predicted points in R1_P40_8_90\n",
      "box: no predicted points in R2_P25_4\n",
      "box: no predicted points in R5_P25_5\n",
      "box: no predicted points in R4_P25_1_270\n",
      "box: no predicted points in R2_P40_0_180\n",
      "box: no predicted points in R2_P35_10_270\n",
      "box: no predicted points in R4_P40_10_90\n",
      "box: no predicted points in R6_P30_0_90\n",
      "box: no predicted points in R6_P40_9_180\n",
      "box: no predicted points in R2_P30_5_180\n",
      "box: no predicted points in R4_P35_6_90\n",
      "box: no predicted points in R2_P25_11\n",
      "box: no predicted points in R1_P40_2_180\n",
      "box: no predicted points in R5_P35_0_180\n",
      "box: no predicted points in R4_P40_1_180\n",
      "box: no predicted points in R4_P40_2_180\n",
      "box: no predicted points in R5_P30_4\n",
      "box: no predicted points in R2_P25_1_180\n",
      "box: no predicted points in R1_P25_6_270\n",
      "box: no predicted points in R6_P40_4_270\n",
      "box: no predicted points in R1_P30_8_90\n",
      "box: no predicted points in R4_P25_6_180\n",
      "box: no predicted points in R2_P30_0_180\n",
      "box: no predicted points in R1_P25_1_180\n",
      "box: no predicted points in R2_P35_4_90\n",
      "box: no predicted points in R6_P30_4_180\n",
      "box: no predicted points in R1_P40_3_270\n",
      "box: no predicted points in R1_P25_3\n",
      "box: no predicted points in R5_P35_4_270\n",
      "box: no predicted points in R6_P25_8_90\n",
      "box: no predicted points in R6_P40_11_270\n",
      "box: no predicted points in R4_P30_9_180\n",
      "box: no predicted points in R1_P40_9_180\n",
      "box: no predicted points in R4_P35_1_90\n",
      "box: no predicted points in R5_P30_0_270\n",
      "box: no predicted points in R2_P30_11_90\n",
      "box: no predicted points in R1_P25_3_180\n",
      "box: no predicted points in R6_P35_2_180\n",
      "box: no predicted points in R5_P40_10_90\n",
      "box: no predicted points in R2_P30_7\n",
      "box: no predicted points in R4_P30_8_90\n",
      "box: no predicted points in R5_P40_7_90\n",
      "box: no predicted points in R2_P40_10_270\n",
      "box: no predicted points in R6_P35_11_90\n",
      "box: no predicted points in R1_P35_6_270\n",
      "box: no predicted points in R4_P25_10_270\n",
      "box: no predicted points in R5_P30_8_90\n",
      "box: no predicted points in R6_P40_5\n",
      "box: no predicted points in R1_P30_7_90\n",
      "box: no predicted points in R2_P35_8_270\n",
      "box: no predicted points in R6_P25_1_270\n",
      "box: no predicted points in R1_P35_4_180\n",
      "box: no predicted points in R4_P40_7\n",
      "box: no predicted points in R5_P30_1_90\n",
      "box: no predicted points in R5_P35_0_270\n",
      "box: no predicted points in R6_P30_3_270\n",
      "box: no predicted points in R5_P30_9_270\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "#Graph: ev conf threshold:\n",
    "#Graph: checkpoints - this cell is to find out which amount of checkpoints is the best for the model. \n",
    "#Auswertung und erstellen der Statistik über alle Bilder  \n",
    "\n",
    "from pytorchyolo import detect, models\n",
    "import importlib\n",
    "import tools  \n",
    "importlib.reload(tools) \n",
    "from tools import statistix, stat_pic, vis_picture, detect_picture\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "file_val = open(\"data/custom_rot/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "\n",
    "conf_steps = np.arange(0.15, 1.025, 0.025)  # 0.51 to include 0.5\n",
    "#conf_steps = np.unique(np.concatenate((range1, range2)))\n",
    "\n",
    "model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"checkpoints/yolov3_ckpt_100.pth\") #load the trained model with its weights\n",
    "ev_nms_thres=0.1\n",
    "ev_accepted_distance=15\n",
    "x_gpu = \"NVIDIA GeForce MX450\"\n",
    "key= \"ev_conf_thres\"\n",
    "x_epochs=100\n",
    "in_wsl, in_windows = True, True \n",
    "\n",
    "for step in conf_steps: #go through all the checkpoints from 1 to 100 in steps of 5. \n",
    "    #for tracking the compilation time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    all_stats = statistix() # create a statistic object \n",
    "\n",
    "    #now we go through all the pictures we wanna add to the statistics: \n",
    "    # Parameter:\n",
    "    ev_conf_thres=step\n",
    "\n",
    "    for val_file in val_paths:\n",
    "        val_file = val_file.split('/')[-1]\n",
    "        detect_picture(filename= val_file.rstrip(),\n",
    "                    img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\",\n",
    "                    pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/predicted_labels\",\n",
    "                    model = model, #we use the once loaded model from the cell above to not waist time. \n",
    "                    conf_thres=ev_conf_thres,\n",
    "                    nms_thres=ev_nms_thres,\n",
    "                    accepted_distance = ev_accepted_distance,\n",
    "                    stat_all_pics= all_stats, \n",
    "                    show = False\n",
    "                    )\n",
    "\n",
    "    #compilation time\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time \n",
    "\n",
    "    days = duration.days\n",
    "    hours, remainder = divmod(duration.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    duration_str = f\"{days}d/{hours}h/{minutes}m/{seconds}s\"\n",
    "    ev_time=duration_str\n",
    "\n",
    "    print(step)\n",
    "    #print('Duration:', duration_str)\n",
    "    ### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \n",
    "    all_stats.print_values\n",
    "    x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate = all_stats.x_get_values()\n",
    "\n",
    "        # current time \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\") #format the time \n",
    "\n",
    "    with open('train_conf_thres2.csv', 'a', newline='') as file:\n",
    "        writer= csv.writer(file)\n",
    "        writer.writerow([key,\n",
    "                     x_data, rotate, boxsize, x_n_gen, x_bb_gen, x_n_data, xval, xcust_only,\n",
    "                     x_model, x_epochs, x_pretrained_weights, x_multi_scale, x_iou_thres, x_conf_thres, x_nms_thres,\n",
    "                     xseed, x_gpu, current_time, x_train_time,ev_time, k_cross_val, in_wsl, in_windows,\n",
    "                     x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate,\n",
    "                     ev_conf_thres, ev_nms_thres, ev_accepted_distance])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/pytorchyolo/models.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0d/0h/0m/20s\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#Graph: ev nms threshold:\n",
    "#Graph: checkpoints - this cell is to find out which amount of checkpoints is the best for the model. \n",
    "#Auswertung und erstellen der Statistik über alle Bilder  \n",
    "\n",
    "from pytorchyolo import detect, models\n",
    "import importlib\n",
    "import tools  \n",
    "importlib.reload(tools) \n",
    "from tools import statistix, stat_pic, vis_picture\n",
    "from datetime import datetime\n",
    "\n",
    "file_val = open(\"data/custom_rot/valid.txt\", \"r\")\n",
    "val_paths = file_val.readlines()\n",
    "file_val.close()\n",
    "\n",
    "d_steps =  np.arange(50, 51, 1)  # Note: The stop value is exclusive, so use 0.6 to include 0.5\n",
    "\n",
    "\n",
    "for step in d_steps: #go through all the checkpoints from 1 to 100 in steps of 5. \n",
    "    #for tracking the compilation time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    model = models.load_model(\"config/yolov3-tiny-custom.cfg\", \"checkpoints/yolov3_ckpt_100.pth\") #load the trained model with its weights\n",
    "\n",
    "    all_stats = statistix() # create a statistic object \n",
    "\n",
    "    \n",
    "    #now we go through all the pictures we wanna add to the statistics: \n",
    "    # Parameter:\n",
    "    ev_conf_thres=0.01\n",
    "    ev_nms_thres=0.1\n",
    "    ev_accepted_distance=step\n",
    "\n",
    "    for val_file in val_paths:\n",
    "        val_file = val_file.split('/')[-1]\n",
    "        detect_picture(filename= val_file.rstrip(),\n",
    "                    img_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/images\",\n",
    "                    pred_label_path = \"/mnt/c/Users/vinze/Dropbox/Universität/8.Bachelorarbeit/yolo2/PyTorch-YOLOv3/data/custom_rot/predicted_labels\",\n",
    "                    model = model, #we use the once loaded model from the cell above to not waist time. \n",
    "                    conf_thres=ev_conf_thres,\n",
    "                    nms_thres=ev_nms_thres,\n",
    "                    accepted_distance = ev_accepted_distance,\n",
    "                    stat_all_pics= all_stats, \n",
    "                    show = False\n",
    "                    )\n",
    "\n",
    "    #compilation time\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time \n",
    "\n",
    "    days = duration.days\n",
    "    hours, remainder = divmod(duration.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    duration_str = f\"{days}d/{hours}h/{minutes}m/{seconds}s\"\n",
    "    ev_time=duration_str\n",
    "\n",
    "    print('Duration:', duration_str)\n",
    "    print(step)\n",
    "    ### hier müssen wir alle daten noch in Variablen abspeichern um sie in eine xlx datei zu speichern. \n",
    "    all_stats.print_values\n",
    "    x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate = all_stats.x_get_values()\n",
    "    \n",
    "    x_epochs=100\n",
    "\n",
    "    #write to csv: \n",
    "    with open('accepted_distance.csv', 'a', newline='') as file:\n",
    "        writer= csv.writer(file)\n",
    "        writer.writerow([key,\n",
    "                         x_data, rotate, boxsize, x_n_gen, x_bb_gen, x_n_data, xval, xcust_only,\n",
    "                         x_model, x_epochs, x_pretrained_weights, x_multi_scale, x_iou_thres, x_conf_thres, x_nms_thres,\n",
    "                         xseed, x_train_time,ev_time, k_cross_val,\n",
    "                         x_n_not_annotated, x_sens, x_over_det_rate, x_no_hit_p_rate,\n",
    "                         ev_conf_thres, ev_nms_thres, ev_accepted_distance])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "glxinfo | grep \"OpenGL renderer string\" | sed -E 's/.*\\(([^()]*)\\)$/\\1/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "x_iou_thres = 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
